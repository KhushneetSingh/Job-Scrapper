# Growth For Impact â€“ Data & Tech Internship Assignment
**Role:** Data & Tech - Python Internship (Scraping Experience Preferred)  
**Pay:** â‚¹12,000 â€“ â‚¹18,000 â€¢ No equity  
**Organization:** [Growth for Impact](https://growthforimpact.co)

---

## ğŸ“„ Overview
This repository contains my submission for the **Growth For Impact Data & Tech Internship** assignment.  
The goal of this project is to **collect, clean, and structure job posting data** from 150+ company websites to help power a purpose-driven job board.

---

## ğŸ¯ Objective
To build a Python-based data pipeline that:
1. **Enriches** the given dataset with company websites, LinkedIn URLs, and careers pages.  
2. **Scrapes** up to 3 job postings per company from their job listings pages.  
3. **Cleans** and verifies the extracted job data for accuracy and consistency.  
4. **Outputs** a structured Excel file (`enriched_jobs.xlsx`) with two sheets:
   - `Data`: job postings
   - `Methodology`: explanation of the approach, tools, and validation steps.

---

## âš™ï¸ Tech Stack
- **Language:** Python 3.10+
- **Libraries:**
  - `requests`, `BeautifulSoup4` â€“ for static scraping  
  - `playwright` / `selenium` â€“ for dynamic websites  
  - `pandas`, `openpyxl` â€“ for data handling  
  - `tqdm`, `re`, `logging` â€“ for progress tracking and cleaning

---

## ğŸ—ï¸ Project Structure